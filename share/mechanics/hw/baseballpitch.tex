A baseball pitcher throws a pitch clocked at $v_x=73.3\ \text{miles/hour}$.
He throws horizontally. By what amount, $d$, does the
ball drop by the time it reaches home plate, $L=60.0\ \zu{feet}$ away?\\
%
        (a) First find a symbolic answer in terms of $L$, $v_x$, and $g$.\answercheck\hwendpart
%
        (b) Plug in and find a numerical answer. Express your
        answer in units of ft. (Note: 1 foot=12 inches, 1 mile=5280 feet, and
        1 inch=2.54 cm) \answercheck
